#!/usr/bin/env python3
"""
PMOVES â€¢ Consciousness YouTube Ingestion Helper

Reads the consciousness chunks generated by `make harvest-consciousness`,
derives search queries, retrieves authoritative videos from YouTube via yt-dlp,
and invokes the PMOVES.YT service to ingest + emit Geometry Bus packets.

Usage:
  python tools/consciousness_ingest.py \
      --chunks pmoves/data/consciousness/Constellation-Harvest-Regularization/processed-for-rag/embeddings-ready/consciousness-chunks.jsonl \
      --yt-base http://localhost:8077 \
      --namespace pmoves.consciousness \
      --max 3

Prerequisites:
  - PMOVES.YT + ffmpeg-whisper running (`make -C pmoves up-yt`)
  - MinIO credentials configured for pmoves-yt service
  - Optional: yt-dlp installed locally (`pip install yt-dlp`)
"""

from __future__ import annotations

import argparse
import json
import os
import sys
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Iterable, List, Optional

import requests

try:
    import yt_dlp  # type: ignore
except Exception:  # pragma: no cover - allow graceful fallback
    yt_dlp = None


@dataclass
class Chunk:
    chunk_id: str
    title: str
    category: str
    content: str


def read_chunks(path: Path) -> List[Chunk]:
    chunks: List[Chunk] = []
    with path.open("r", encoding="utf-8") as fh:
        for line in fh:
            if not line.strip():
                continue
            payload = json.loads(line)
            chunks.append(
                Chunk(
                    chunk_id=payload["id"],
                    title=payload.get("title") or "Untitled",
                    category=payload.get("category") or "general",
                    content=payload.get("content") or "",
                )
            )
    return chunks


def load_video_map(path: Path) -> Dict[str, Dict[str, str]]:
    if not path.exists():
        return {}
    try:
        data = json.loads(path.read_text(encoding="utf-8"))
        return {entry["chunk_id"]: entry for entry in data}
    except Exception:
        return {}


def save_video_map(path: Path, mapping: Dict[str, Dict[str, str]]) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    payload = sorted(mapping.values(), key=lambda x: x["chunk_id"])
    path.write_text(json.dumps(payload, ensure_ascii=False, indent=2) + "\n", encoding="utf-8")


def search_video(query: str, max_results: int = 5) -> Optional[Dict[str, str]]:
    if yt_dlp is None:
        raise RuntimeError("yt-dlp is not installed. Install via `pip install yt-dlp`.")

    ydl_opts = {
        "quiet": True,
        "skip_download": True,
        "default_search": "ytsearch",
        "extract_flat": "in_playlist",
    }
    search_term = f"ytsearch{max_results}:{query}"
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        info = ydl.extract_info(search_term, download=False)
    entries = info.get("entries") or []
    for entry in entries:
        if entry.get("_type") == "url":
            continue  # playlist or channel
        if entry.get("id") and entry.get("webpage_url"):
            return {
                "id": entry["id"],
                "url": entry["webpage_url"],
                "title": entry.get("title", ""),
                "duration": entry.get("duration"),
                "channel": entry.get("channel"),
                "uploader": entry.get("uploader"),
            }
    return None


def ensure_health(base_url: str) -> None:
    try:
        resp = requests.get(f"{base_url.rstrip('/')}/healthz", timeout=5)
        resp.raise_for_status()
    except Exception as exc:  # pragma: no cover
        raise RuntimeError(f"pmoves-yt health check failed ({exc}). Ensure `make -C pmoves up-yt` is running.")


def ingest_video(base_url: str, video_info: Dict[str, str], namespace: str, chunk: Chunk, dry_run: bool = False) -> None:
    ingest_payload = {
        "url": video_info["url"],
        "namespace": namespace,
        "persona": chunk.category,
        "metadata": {
            "chunk_id": chunk.chunk_id,
            "source": "pmoves.consciousness",
            "discovery_query": video_info.get("query"),
        },
    }
    if dry_run:
        print(f"[dry-run] Would POST /yt/ingest -> {ingest_payload}")
        return

    resp = requests.post(
        f"{base_url.rstrip('/')}/yt/ingest",
        json=ingest_payload,
        timeout=60 * 30,  # allow lengthy downloads
    )
    if resp.status_code >= 400:
        raise RuntimeError(f"Ingest failed ({resp.status_code}): {resp.text}")

    emit_payload = {
        "video_id": video_info["id"],
        "namespace": namespace,
        "chunk_id": chunk.chunk_id,
    }
    resp = requests.post(f"{base_url.rstrip('/')}/yt/emit", json=emit_payload, timeout=60)
    if resp.status_code >= 400:
        raise RuntimeError(f"Emit failed ({resp.status_code}): {resp.text}")


def build_query(chunk: Chunk) -> str:
    tail = "interview"
    if chunk.category and chunk.category not in chunk.title.lower():
        tail = f"{chunk.category} interview"
    return f"{chunk.title} {tail}"


def run_ingestion(
    chunks: Iterable[Chunk],
    base_url: str,
    namespace: str,
    mapping_path: Path,
    max_videos: Optional[int],
    dry_run: bool,
) -> None:
    if not dry_run:
        ensure_health(base_url)
    mapping = load_video_map(mapping_path)
    processed = 0

    for chunk in chunks:
        if max_videos is not None and processed >= max_videos:
            break
        if chunk.chunk_id in mapping:
            print(f"[skip] {chunk.chunk_id} already ingested ({mapping[chunk.chunk_id]['video_id']})")
            continue

        query = build_query(chunk)
        print(f"[search] chunk={chunk.chunk_id} query='{query}'")
        try:
            video = search_video(query)
        except RuntimeError as exc:
            print(f"[error] {exc}")
            return

        if not video:
            print(f"[warn] No video found for {chunk.chunk_id}")
            continue

        video["query"] = query
        print(f"[found] {video['title']} ({video['url']})")

        try:
            ingest_video(base_url, video, namespace, chunk, dry_run=dry_run)
        except Exception as exc:
            print(f"[error] ingest failed for {video['url']}: {exc}")
            continue

        mapping[chunk.chunk_id] = {
            "chunk_id": chunk.chunk_id,
            "video_id": video["id"],
            "video_url": video["url"],
            "video_title": video.get("title", ""),
            "channel": video.get("channel") or video.get("uploader"),
            "query": query,
            "namespace": namespace,
            "ingested_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        }
        save_video_map(mapping_path, mapping)
        processed += 1
        print(f"[ok] Ingested video_id={video['id']} for chunk={chunk.chunk_id}")

    if processed == 0:
        print("[info] No new videos ingested.")
    else:
        print(f"[done] Ingested {processed} video(s). Mapping stored at {mapping_path}")


def parse_args(argv: Optional[List[str]] = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=__doc__)
    default_chunks = Path(
        "pmoves/data/consciousness/Constellation-Harvest-Regularization/processed-for-rag/embeddings-ready/consciousness-chunks.jsonl"
    )
    parser.add_argument("--chunks", type=Path, default=default_chunks, help="Path to consciousness chunks JSONL")
    parser.add_argument("--yt-base", default=os.environ.get("PMOVES_YT_URL", "http://localhost:8077"), help="pmoves-yt base URL")
    parser.add_argument("--namespace", default="pmoves.consciousness", help="Namespace for PMOVES.YT ingest")
    parser.add_argument("--max", type=int, default=None, help="Maximum number of new videos to ingest (default: all)")
    parser.add_argument("--dry-run", action="store_true", help="Do not call pmoves-yt, just print planned actions")
    parser.add_argument("--mapping", type=Path, default=None, help="Override path for video mapping JSON")
    return parser.parse_args(argv)


def main(argv: Optional[List[str]] = None) -> int:
    args = parse_args(argv)
    chunks_file = args.chunks
    if not chunks_file.exists():
        print(f"[error] chunks file not found: {chunks_file}", file=sys.stderr)
        return 1

    chunks = read_chunks(chunks_file)
    mapping_path = (
        args.mapping
        if args.mapping
        else chunks_file.parent.parent / "supabase-import" / "consciousness-video-sources.json"
    )

    run_ingestion(
        chunks=chunks,
        base_url=args.yt_base,
        namespace=args.namespace,
        mapping_path=mapping_path,
        max_videos=args.max,
        dry_run=args.dry_run,
    )
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
