# Retrieval Eval Datasets

This folder stores JSONL query sets derived from synced notebooks. Each dataset is generated by running `export_notebooks.py` over the sync worker payloads alongside the associated extract-worker chunk exports.

## Available datasets

- `notebook_queries.sample.jsonl` â€” small smoke dataset sourced from the Doc2Structure walkthrough notebook. Gold chunk IDs align with the docs seeded by `hi-rag-gateway-v2/scripts/seed_local.py`.

## Refreshing datasets

1. Pull the latest synced notebook payloads (see `../README.md` for the sync workflow).
2. Collect the extract-worker payloads that contain the chunk IDs you want to validate against.
3. Run the exporter, pointing to both locations:

   ```bash
   python pmoves/services/retrieval-eval/export_notebooks.py \
     --source pmoves/services/retrieval-eval/datasets/source/notebook_sync.sample.json \
     --chunks pmoves/services/retrieval-eval/datasets/source/extract_payload.sample.json \
     --output pmoves/services/retrieval-eval/datasets/notebook_queries.sample.jsonl
   ```

   Use `--strict` to fail on missing chunk IDs. Without `--strict`, the script prints warnings for unmatched IDs.

4. Commit the refreshed JSONL files together with the sync/export payload snapshots to keep diffs reviewable.
