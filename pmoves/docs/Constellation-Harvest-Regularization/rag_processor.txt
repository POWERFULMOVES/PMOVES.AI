# RAG Data Processor for Consciousness Database
# Prepares downloaded consciousness theories for Supabase + Hugging Face embeddings
# For Russell's PMOVES.AI project

param(
    [string]$SourcePath = "C:\Users\russe\Documents\GitHub\PMOVES.AI\pmoves\docs\Constellation-Harvest-Regularization",
    [string]$OutputPath = "C:\Users\russe\Documents\GitHub\PMOVES.AI\pmoves\docs\Constellation-Harvest-Regularization\processed-for-rag",
    [int]$ChunkSize = 512,
    [int]$OverlapSize = 50
)

# Function to sanitize filenames for Windows
function Get-SafeFileName {
    param([string]$FileName)
    $invalidChars = [IO.Path]::GetInvalidFileNameChars()
    $sanitized = $FileName
    foreach ($char in $invalidChars) {
        $sanitized = $sanitized.Replace($char, '-')
    }
    return $sanitized -replace '\s+', '-' -replace '-+', '-'
}

# Function to chunk text for optimal embedding
function Split-TextIntoChunks {
    param(
        [string]$Text,
        [int]$ChunkSize,
        [int]$OverlapSize
    )
    
    $chunks = @()
    $words = $Text -split '\s+'
    $currentChunk = @()
    $currentLength = 0
    
    foreach ($word in $words) {
        if (($currentLength + $word.Length) -gt $ChunkSize -and $currentChunk.Count -gt 0) {
            # Create chunk with overlap
            $chunkText = ($currentChunk -join ' ')
            $chunks += $chunkText
            
            # Keep overlap words for next chunk
            $overlapWords = $currentChunk | Select-Object -Last $OverlapSize
            $currentChunk = $overlapWords + @($word)
            $currentLength = ($overlapWords -join ' ').Length + $word.Length
        } else {
            $currentChunk += $word
            $currentLength += $word.Length + 1
        }
    }
    
    # Add final chunk
    if ($currentChunk.Count -gt 0) {
        $chunks += ($currentChunk -join ' ')
    }
    
    return $chunks
}

# Function to extract structured data from HTML
function Extract-StructuredData {
    param([string]$HtmlContent, [string]$SourceFile)
    
    # Basic HTML parsing - extract text content
    $textContent = $HtmlContent -replace '<[^>]+>', ' ' -replace '\s+', ' '
    $textContent = [System.Web.HttpUtility]::HtmlDecode($textContent).Trim()
    
    # Extract metadata
    $metadata = @{
        source_file = $SourceFile
        extraction_date = (Get-Date).ToString("yyyy-MM-ddTHH:mm:ssZ")
        content_type = "consciousness_theory"
        word_count = ($textContent -split '\s+').Count
        char_count = $textContent.Length
    }
    
    return @{
        content = $textContent
        metadata = $metadata
    }
}

# Create output directory structure
Write-Host "=== RAG Data Processor for Consciousness Database ===" -ForegroundColor Cyan
Write-Host "Processing data for Supabase + Hugging Face embeddings..." -ForegroundColor Yellow

if (-not (Test-Path $OutputPath)) {
    New-Item -ItemType Directory -Path $OutputPath -Force
}

$subdirs = @("chunks", "metadata", "embeddings-ready", "supabase-import")
foreach ($subdir in $subdirs) {
    $path = Join-Path $OutputPath $subdir
    if (-not (Test-Path $path)) {
        New-Item -ItemType Directory -Path $path -Force
    }
}

# Process downloaded HTML files
$htmlFiles = Get-ChildItem -Path $SourcePath -Recurse -Filter "*.html"
$allChunks = @()
$documentIndex = 0

Write-Host "`nProcessing $($htmlFiles.Count) HTML files..." -ForegroundColor Green

foreach ($file in $htmlFiles) {
    Write-Host "Processing: $($file.Name)" -ForegroundColor Yellow
    
    try {
        $htmlContent = Get-Content -Path $file.FullName -Raw -Encoding UTF8
        $extracted = Extract-StructuredData -HtmlContent $htmlContent -SourceFile $file.FullName
        
        if ($extracted.content.Length -gt 100) {  # Skip very short content
            # Create chunks
            $chunks = Split-TextIntoChunks -Text $extracted.content -ChunkSize $ChunkSize -OverlapSize $OverlapSize
            
            for ($i = 0; $i -lt $chunks.Count; $i++) {
                $chunkId = "doc_$($documentIndex)_chunk_$i"
                $chunk = @{
                    id = $chunkId
                    document_id = $documentIndex
                    chunk_index = $i
                    text = $chunks[$i]
                    metadata = $extracted.metadata
                    theory_category = $null
                    theory_subcategory = $null
                    source_url = $null
                    embedding_vector = $null  # To be filled by Hugging Face
                }
                
                # Infer category from file path
                if ($file.DirectoryName -match "materialism|quantum|panpsychism|dualism|idealism") {
                    $pathParts = $file.DirectoryName -split '\\'
                    $categoryIndex = $pathParts.IndexOf("theories")
                    if ($categoryIndex -ge 0 -and $categoryIndex + 1 -lt $pathParts.Count) {
                        $chunk.theory_category = $pathParts[$categoryIndex + 1]
                        if ($categoryIndex + 2 -lt $pathParts.Count) {
                            $chunk.theory_subcategory = $pathParts[$categoryIndex + 2]
                        }
                    }
                }
                
                $allChunks += $chunk
            }
            
            $documentIndex++
        }
    }
    catch {
        Write-Warning "Failed to process $($file.Name): $($_.Exception.Message)"
    }
}

# Save chunks for embedding
Write-Host "`nSaving $($allChunks.Count) chunks for embedding..." -ForegroundColor Green

# Create JSONL file for Hugging Face processing
$jsonlPath = Join-Path $OutputPath "embeddings-ready\consciousness-chunks.jsonl"
foreach ($chunk in $allChunks) {
    $json = $chunk | ConvertTo-Json -Compress
    Add-Content -Path $jsonlPath -Value $json -Encoding UTF8
}

# Create CSV for easy import
$csvPath = Join-Path $OutputPath "embeddings-ready\consciousness-chunks.csv"
$allChunks | Export-Csv -Path $csvPath -NoTypeInformation -Encoding UTF8

# Create Supabase table schema
$supabaseSchema = @"
-- Supabase table schema for consciousness theories
-- For Russell's hybrid search setup with pgvector

CREATE EXTENSION IF NOT EXISTS vector;
CREATE EXTENSION IF NOT EXISTS timescaledb;

-- Main consciousness theories table
CREATE TABLE consciousness_theories (
    id SERIAL PRIMARY KEY,
    chunk_id TEXT UNIQUE NOT NULL,
    document_id INTEGER NOT NULL,
    chunk_index INTEGER NOT NULL,
    text TEXT NOT NULL,
    theory_category TEXT,
    theory_subcategory TEXT,
    source_file TEXT,
    source_url TEXT,
    word_count INTEGER,
    char_count INTEGER,
    embedding vector(3584), -- Hugging Face embedding dimension
    metadata JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Indexes for hybrid search
CREATE INDEX idx_consciousness_theories_embedding ON consciousness_theories 
USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);

CREATE INDEX idx_consciousness_theories_text ON consciousness_theories 
USING gin(to_tsvector('english', text));

CREATE INDEX idx_consciousness_theories_category ON consciousness_theories (theory_category);
CREATE INDEX idx_consciousness_theories_subcategory ON consciousness_theories (theory_subcategory);
CREATE INDEX idx_consciousness_theories_chunk_id ON consciousness_theories (chunk_id);

-- Function for hybrid search (semantic + keyword)
CREATE OR REPLACE FUNCTION hybrid_search_consciousness(
    query_text TEXT,
    query_embedding vector(3584),
    semantic_weight FLOAT DEFAULT 0.7,
    keyword_weight FLOAT DEFAULT 0.3,
    match_limit INT DEFAULT 10
)
RETURNS TABLE(
    chunk_id TEXT,
    text TEXT,
    theory_category TEXT,
    theory_subcategory TEXT,
    semantic_similarity FLOAT,
    keyword_rank FLOAT,
    combined_score FLOAT
)
LANGUAGE plpgsql
AS $function$
BEGIN
    RETURN QUERY
    SELECT 
        ct.chunk_id,
        ct.text,
        ct.theory_category,
        ct.theory_subcategory,
        (1 - (ct.embedding <=> query_embedding)) AS semantic_similarity,
        ts_rank(to_tsvector('english', ct.text), plainto_tsquery('english', query_text)) AS keyword_rank,
        (semantic_weight * (1 - (ct.embedding <=> query_embedding))) + 
        (keyword_weight * ts_rank(to_tsvector('english', ct.text), plainto_tsquery('english', query_text))) AS combined_score
    FROM consciousness_theories ct
    WHERE 
        to_tsvector('english', ct.text) @@ plainto_tsquery('english', query_text)
        OR (ct.embedding <=> query_embedding) < 0.5
    ORDER BY combined_score DESC
    LIMIT match_limit;
END;
$function$;

-- Theory categories lookup table
CREATE TABLE theory_categories (
    id SERIAL PRIMARY KEY,
    category_name TEXT UNIQUE NOT NULL,
    description TEXT,
    physicalist_spectrum FLOAT, -- 0.0 = most physical, 1.0 = least physical
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Insert main categories with physicalist spectrum positioning
INSERT INTO theory_categories (category_name, description, physicalist_spectrum) VALUES
('Materialism-Theories', 'Consciousness is entirely physical, product of biological brains', 0.1),
('Non-Reductive-Physicalism', 'Physical but not reducible to basic physics', 0.2),
('Quantum-Theories', 'Quantum mechanics plays role in consciousness', 0.4),
('Integrated-Information-Theory', 'Consciousness corresponds to integrated information', 0.3),
('Panpsychisms', 'Consciousness is fundamental property of matter', 0.6),
('Monisms', 'Reality has single fundamental nature', 0.7),
('Dualisms', 'Mind and matter are distinct substances', 0.8),
('Idealisms', 'Reality is fundamentally mental', 0.9),
('Anomalous-Altered-States', 'Non-ordinary states of consciousness', 0.5),
('Challenge-Theories', 'Challenge conventional assumptions about consciousness', 0.5);

-- View for theory analysis
CREATE VIEW consciousness_theory_analysis AS
SELECT 
    ct.theory_category,
    COUNT(*) as chunk_count,
    AVG(ct.word_count) as avg_word_count,
    tc.physicalist_spectrum,
    tc.description
FROM consciousness_theories ct
LEFT JOIN theory_categories tc ON ct.theory_category = tc.category_name
GROUP BY ct.theory_category, tc.physicalist_spectrum, tc.description
ORDER BY tc.physicalist_spectrum;
"@

$schemaPath = Join-Path $OutputPath "supabase-import\consciousness-schema.sql"
$supabaseSchema | Out-File -FilePath $schemaPath -Encoding UTF8

# Create n8n workflow template
$n8nWorkflow = @{
    "name" = "Consciousness Theories RAG Pipeline"
    "nodes" = @(
        @{
            "name" = "Load Text Chunks"
            "type" = "n8n-nodes-base.readBinaryFile"
            "parameters" = @{
                "filePath" = $jsonlPath
            }
        },
        @{
            "name" = "Generate Embeddings"
            "type" = "n8n-nodes-base.huggingFace"
            "parameters" = @{
                "model" = "sentence-transformers/all-MiniLM-L6-v2"
                "task" = "feature-extraction"
            }
        },
        @{
            "name" = "Store in Supabase"
            "type" = "n8n-nodes-base.supabase"
            "parameters" = @{
                "table" = "consciousness_theories"
                "operation" = "insert"
            }
        }
    )
}

$n8nPath = Join-Path $OutputPath "supabase-import\n8n-workflow.json"
$n8nWorkflow | ConvertTo-Json -Depth 10 | Out-File -FilePath $n8nPath -Encoding UTF8

# Create summary report
$summaryReport = @"
# Consciousness Database RAG Processing Report

**Generated:** $(Get-Date)
**Source Path:** $SourcePath
**Output Path:** $OutputPath

## Processing Summary

- **Total HTML files processed:** $($htmlFiles.Count)
- **Total text chunks created:** $($allChunks.Count)
- **Average chunk size:** $([math]::Round(($allChunks | Measure-Object -Property {$_.text.Length} -Average).Average)) characters
- **Chunk size target:** $ChunkSize characters
- **Overlap size:** $OverlapSize characters

## Theory Categories Detected

$($allChunks | Where-Object {$_.theory_category} | Group-Object theory_category | ForEach-Object {"- **$($_.Name):** $($_.Count) chunks"} | Out-String)

## Files Generated

### For Embedding Generation
- **JSONL format:** embeddings-ready/consciousness-chunks.jsonl
- **CSV format:** embeddings-ready/consciousness-chunks.csv

### For Supabase Import  
- **Database schema:** supabase-import/consciousness-schema.sql
- **n8n workflow:** supabase-import/n8n-workflow.json

## Next Steps for RAG Integration

1. **Generate Embeddings:**
   - Use Hugging Face API with the JSONL file
   - Model: sentence-transformers/all-MiniLM-L6-v2 (or your preferred 3584-dim model)
   
2. **Set up Supabase:**
   - Run the SQL schema in your Supabase instance
   - Ensure pgvector and TimescaleDB extensions are enabled
   
3. **Import Data:**
   - Use the n8n workflow or import CSV directly
   - Add embeddings to the vector column
   
4. **Test Hybrid Search:**
   - Use the provided hybrid_search_consciousness() function
   - Combine semantic similarity with keyword matching
   
5. **Integration with PMOVES.AI:**
   - Connect to your existing RAG pipeline
   - Use for consciousness-related queries
   - Enhance AI development insights

## Recommended Query Patterns

- **Semantic:** Find theories similar to user's conceptual queries
- **Categorical:** Filter by physicalist spectrum or theory type  
- **Hybrid:** Combine semantic + keyword for comprehensive results
- **Temporal:** Track theoretical development and relationships

## Data Quality Notes

- Content extracted from HTML with basic cleaning
- Category inference based on directory structure
- Manual review recommended for critical applications
- Chunking optimized for embedding model context window

---
Ready for integration with Russell's Supabase + Hugging Face RAG system
"@

$reportPath = Join-Path $OutputPath "processing-report.md"
$summaryReport | Out-File -FilePath $reportPath -Encoding UTF8

Write-Host "`n=== RAG Processing Complete ===" -ForegroundColor Green
Write-Host "Output directory: $OutputPath" -ForegroundColor Green
Write-Host "`nGenerated files:" -ForegroundColor Yellow
Write-Host "✓ $($allChunks.Count) text chunks ready for embedding" -ForegroundColor White
Write-Host "✓ Supabase schema with hybrid search functions" -ForegroundColor White  
Write-Host "✓ n8n workflow template" -ForegroundColor White
Write-Host "✓ Processing report and documentation" -ForegroundColor White

Write-Host "`nNext: Generate embeddings and import to Supabase!" -ForegroundColor Cyan