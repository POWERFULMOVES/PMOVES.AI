# ===== Codex config.toml (Windows) =====
# Place at: C:\Users\russe\.codex\config.toml

# ---- Defaults (used if no profile is specified) ----
model = "gpt-5"
model_provider = "openai"

[tools]
web_search = true

# Default permissions: SEARCH + workspace WRITE sandbox with network allowed
# Prompted approvals for risky ops remain (on-request).
approval_policy = "on-request"
sandbox_mode    = "workspace-write"

[sandbox_workspace_write]
# Network allowed by default (web.run, package installs, etc.)
network_access = true
# Writable roots for day-to-day work. Adjust to your username/paths as needed.
writable_roots = [
  "C\\:\\\Users\\russe",
  "C\\:\\\Users\\russe\\Documents\\GitHub",
  "C\\:\\\Users\\russe\\AppData\\Local",
  "C\\:\\\ProgramData"
]

[shell_environment_policy]
inherit = "all"
ignore_default_excludes = true

# ---- MCP servers (stdio) ----
[mcp_servers.MCP_DOCKER]
command = "docker"
args    = ["mcp", "gateway", "run"]

[mcp_servers.MCP_DOCKER.env]
LOCALAPPDATA = "C:\\Users\\russe\\AppData\\Local"
ProgramData  = "C:\\ProgramData"
ProgramFiles = "C:\\Program Files"

# ---- Optional: local model provider for Codex (Ollama) ----
[model_providers.ollama]
name     = "Ollama"
base_url = "http://localhost:11434/v1"

# ================== PROFILES ==================

# 1) web-auto: workspace writes + network ON, auto-approve
[profiles.web-auto]
approval_policy = "never"
sandbox_mode    = "workspace-write"
[profiles.web-auto.sandbox_workspace_write]
network_access = true
writable_roots = [
  "C:\\Users\\russe",
  "C:\\Users\\russe\\Documents\\GitHub",
  "C:\\Users\\russe\\AppData\\Local",
  "C:\\ProgramData"
]

# 2) full-send: total access (no sandbox) â€” be careful!
[profiles.full-send]
approval_policy = "never"
sandbox_mode    = "danger-full-access"

# 3) mcp-only: tighter writes aligned with MCP paths
[profiles.mcp-only]
approval_policy = "never"
sandbox_mode    = "workspace-write"
[profiles.mcp-only.sandbox_workspace_write]
network_access = true
writable_roots = [
  "C:\\Users\\russe\\Documents\\GitHub",
  "C:\\Users\\russe\\AppData\\Local",
  "C:\\ProgramData"
]

# 4) dev: use local model via Ollama for Codex itself
[profiles.dev]
approval_policy = "never"
sandbox_mode    = "workspace-write"
model_provider  = "ollama"
model           = "qwen2.5:7b-instruct"
[profiles.dev.sandbox_workspace_write]
network_access = true
writable_roots = [
  "C:\\Users\\russe\\Documents\\GitHub",
  "C:\\Users\\russe\\AppData\\Local",
  "C:\\ProgramData"
]
