{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "Agent RL Training Request",
  "description": "Request to trigger RL training job with specified parameters",
  "type": "object",
  "required": [
    "training_job_id",
    "timestamp",
    "requester",
    "trigger_reason",
    "training_config"
  ],
  "properties": {
    "training_job_id": {
      "type": "string",
      "format": "uuid",
      "description": "Unique identifier for this training job"
    },
    "timestamp": {
      "type": "string",
      "format": "date-time",
      "description": "Request timestamp (ISO 8601)"
    },
    "requester": {
      "type": "string",
      "description": "Entity requesting training",
      "examples": ["rl-trainer-subordinate", "user-manual", "scheduled-job"]
    },
    "trigger_reason": {
      "type": "string",
      "enum": ["scheduled", "threshold_reached", "manual", "performance_degradation"],
      "description": "Reason for triggering training"
    },
    "training_config": {
      "type": "object",
      "required": ["algorithm", "base_model", "dataset", "hyperparameters"],
      "properties": {
        "algorithm": {
          "type": "string",
          "enum": ["ppo", "dpo", "rloo", "grpo", "reinforce"],
          "description": "RL algorithm to use"
        },
        "base_model": {
          "type": "string",
          "description": "Base model to fine-tune",
          "examples": ["qwen2.5-32b-instruct", "qwen2.5-14b-instruct"]
        },
        "dataset": {
          "type": "object",
          "required": ["source", "sample_size"],
          "properties": {
            "source": {
              "type": "string",
              "enum": ["nats_stream", "clickhouse", "s3", "local"],
              "description": "Data source for trajectories"
            },
            "stream_name": {
              "type": "string",
              "description": "NATS stream name if source=nats_stream"
            },
            "filter": {
              "type": "object",
              "description": "Filters to apply to dataset",
              "properties": {
                "min_reward": {
                  "type": "number",
                  "description": "Minimum reward threshold"
                },
                "max_trajectory_length": {
                  "type": "integer",
                  "minimum": 1,
                  "description": "Maximum number of turns"
                },
                "date_range": {
                  "type": "object",
                  "properties": {
                    "start": {
                      "type": "string",
                      "format": "date-time"
                    },
                    "end": {
                      "type": "string",
                      "format": "date-time"
                    }
                  }
                },
                "task_domains": {
                  "type": "array",
                  "items": {
                    "type": "string",
                    "enum": ["coding", "research", "data_analysis", "general", "debugging", "writing"]
                  },
                  "description": "Include only these task domains"
                },
                "exclude_subordinate_profiles": {
                  "type": "array",
                  "items": {"type": "string"},
                  "description": "Exclude trajectories from these subordinate profiles"
                }
              }
            },
            "sample_size": {
              "type": "integer",
              "minimum": 1,
              "description": "Number of trajectories to use"
            }
          }
        },
        "hyperparameters": {
          "type": "object",
          "properties": {
            "learning_rate": {
              "type": "number",
              "minimum": 0,
              "exclusiveMinimum": true,
              "description": "Learning rate"
            },
            "batch_size": {
              "type": "integer",
              "minimum": 1,
              "description": "Training batch size"
            },
            "epochs": {
              "type": "integer",
              "minimum": 1,
              "description": "Number of training epochs"
            },
            "clip_epsilon": {
              "type": "number",
              "minimum": 0,
              "description": "PPO clipping epsilon"
            },
            "gamma": {
              "type": "number",
              "minimum": 0,
              "maximum": 1,
              "description": "Discount factor"
            },
            "gae_lambda": {
              "type": "number",
              "minimum": 0,
              "maximum": 1,
              "description": "GAE lambda parameter"
            }
          }
        },
        "compute": {
          "type": "object",
          "description": "Compute resource requirements",
          "properties": {
            "gpu_count": {
              "type": "integer",
              "minimum": 0,
              "description": "Number of GPUs to use"
            },
            "gpu_type": {
              "type": "string",
              "description": "GPU type requirement",
              "examples": ["a100", "v100", "t4", "any"]
            },
            "distributed": {
              "type": "boolean",
              "description": "Use distributed training"
            },
            "mixed_precision": {
              "type": "string",
              "enum": ["fp32", "fp16", "bf16"],
              "description": "Mixed precision training mode"
            }
          }
        },
        "checkpointing": {
          "type": "object",
          "description": "Checkpoint saving configuration",
          "properties": {
            "save_interval": {
              "type": "integer",
              "minimum": 1,
              "description": "Save checkpoint every N steps"
            },
            "max_checkpoints": {
              "type": "integer",
              "minimum": 1,
              "description": "Maximum number of checkpoints to keep"
            },
            "storage_path": {
              "type": "string",
              "description": "S3/MinIO path for checkpoints",
              "examples": ["s3://pmoves-models/rl-checkpoints/"]
            }
          }
        }
      }
    },
    "evaluation": {
      "type": "object",
      "description": "Evaluation configuration",
      "properties": {
        "enabled": {
          "type": "boolean",
          "description": "Enable evaluation during training"
        },
        "holdout_size": {
          "type": "number",
          "minimum": 0,
          "maximum": 1,
          "description": "Fraction of data to hold out for evaluation"
        },
        "metrics": {
          "type": "array",
          "items": {
            "type": "string",
            "enum": ["reward", "task_completion", "efficiency", "loss", "kl_divergence"]
          },
          "description": "Metrics to compute during evaluation"
        },
        "benchmark_tasks": {
          "type": "array",
          "items": {"type": "string"},
          "description": "Standard benchmark tasks to evaluate on"
        }
      }
    },
    "priority": {
      "type": "string",
      "enum": ["low", "normal", "high", "urgent"],
      "default": "normal",
      "description": "Training job priority"
    },
    "metadata": {
      "type": "object",
      "description": "Additional metadata",
      "properties": {
        "requested_by": {
          "type": "string",
          "description": "User ID or system identifier"
        },
        "previous_training_job": {
          "type": ["string", "null"],
          "format": "uuid",
          "description": "Reference to previous training job if incremental"
        },
        "notes": {
          "type": "string",
          "description": "Optional description or notes"
        }
      }
    }
  },
  "additionalProperties": false
}
