# Core data services
QDRANT_URL=http://qdrant:6333
QDRANT_COLLECTION=pmoves_chunks
MEILI_MASTER_KEY=master_key
NEO4J_URL=bolt://neo4j:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=neo4j

# Hi‑RAG v2 (gateway)
SENTENCE_MODEL=all-MiniLM-L6-v2
INDEXER_NAMESPACE=pmoves
RERANK_ENABLE=true
RERANK_MODEL=BAAI/bge-reranker-base
RERANK_TOPN=50
RERANK_K=10
HIRAG_RERANK_ENABLED=true
HIRAG_HTTP_PORT=8086
GRAPH_BOOST=0.15
ENTITY_CACHE_TTL=60
ENTITY_CACHE_MAX=1000
NEO4J_DICT_REFRESH_SEC=60
NEO4J_DICT_LIMIT=50000
USE_MEILI=false
MEILI_URL=http://meilisearch:7700
TAILSCALE_ONLY=false            # true => gate every endpoint (REST + WS) behind the Tailnet
TAILSCALE_ADMIN_ONLY=false      # true => gate only admin/ingest endpoints when TAILSCALE_ONLY=false
TAILSCALE_CIDRS=100.64.0.0/10

# Embedding providers (local-first order)
# 1) Ollama (local)
OLLAMA_URL=http://ollama:11434
OLLAMA_EMBED_MODEL=nomic-embed-text
# 2) OpenAI-compatible (LM Studio / vLLM / NVIDIA NIM)
OPENAI_COMPAT_BASE_URL=
OPENAI_COMPAT_API_KEY=
OPENAI_COMPAT_EMBED_MODEL=text-embedding-3-small
# 3) Hugging Face Inference
HF_API_KEY=
HF_EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Retrieval Eval
EVAL_HTTP_PORT=8090

# MinIO / Presign
MINIO_ENDPOINT=minio:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_SECURE=false
FRAME_BUCKET=assets
AWS_DEFAULT_REGION=us-east-1
ALLOWED_BUCKETS=assets,outputs
PRESIGN_SHARED_SECRET=change_me
# PDF ingest defaults
PDF_DEFAULT_BUCKET=assets
PDF_DEFAULT_NAMESPACE=pmoves
PDF_MAX_PAGES=0
PDF_INGEST_EXTRACT_URL=http://extract-worker:8083/ingest

# Supabase / PostgREST
POSTGRES_DB=pmoves
POSTGRES_USER=pmoves
POSTGRES_PASSWORD=pmoves
PGRST_DB_SCHEMA=public,pmoves_core
PGRST_DB_ANON_ROLE=anon
SUPA_REST_URL=http://postgrest:3000
# Alias for n8n flows and external tools
SUPABASE_REST_URL=http://postgrest:3000
# Full Supabase (optional; see docs/SUPABASE_FULL.md)
SUPABASE_JWT_SECRET=dev_jwt_secret
SUPABASE_ANON_KEY=dev_anon_key
SUPABASE_SERVICE_ROLE_KEY=dev_service_key
SUPABASE_REALTIME_SECRET=dev_realtime_secret
GOTRUE_SITE_URL=http://localhost:54323
SUPABASE_STORAGE_URL=http://storage:5000
SUPABASE_PUBLIC_STORAGE_BASE=http://localhost:5000

# NATS (events / mesh)
NATS_URL=nats://nats:4222

# PMOVES.YT (YouTube ingestion & summarization)
YT_BUCKET=assets
FFW_URL=http://ffmpeg-whisper:8078
HIRAG_URL=http://hi-rag-gateway-v2:8086
YT_SUMMARY_PROVIDER=ollama   # ollama|hf
YT_GEMMA_MODEL=gemma2:9b-instruct
HF_GEMMA_MODEL=google/gemma-2-9b-it
HF_USE_GPU=false
HF_TOKEN=
YT_PLAYLIST_MAX=50
YT_CONCURRENCY=2
YT_RATE_LIMIT=0.0
# Smart segmentation (autotune default true)
YT_SEG_AUTOTUNE=true
YT_SEG_TARGET_DUR=30.0
YT_SEG_GAP_THRESH=1.2
YT_SEG_MIN_CHARS=600
YT_SEG_MAX_CHARS=1500
YT_SEG_MAX_DUR=60.0
YT_INDEX_LEXICAL=true

# Geometry Bus (CHIT) — security/decoders (gateway)
CHIT_REQUIRE_SIGNATURE=false
CHIT_PASSPHRASE=
CHIT_DECRYPT_ANCHORS=false
CHIT_DECODE_TEXT=false
CHIT_DECODE_IMAGE=false
CHIT_DECODE_AUDIO=false
CHIT_CODEBOOK_PATH=datasets/structured_dataset.jsonl
CHIT_T5_MODEL=t5-small
CHIT_CLIP_MODEL=clip-ViT-B-32
CHIT_PERSIST_DB=false
# When persisting to DB is enabled, set PG creds (defaults below if using docker compose postgres)
PGHOST=postgres
PGPORT=5432
PGUSER=pmoves
PGPASSWORD=pmoves
PGDATABASE=pmoves

# Discord Publisher
DISCORD_WEBHOOK_URL=
# Preferred for n8n echo publisher webhook username
DISCORD_WEBHOOK_USERNAME=PMOVES Publisher
# Backwards-compat for services/publisher-discord
DISCORD_USERNAME=PMOVES
DISCORD_AVATAR_URL=
DISCORD_SUBJECTS=ingest.file.added.v1,ingest.transcript.ready.v1,ingest.summary.ready.v1,ingest.chapters.ready.v1

# Publisher workflow toggles
PUBLISHER_NOTIFY_DISCORD_WEBHOOK=
PUBLISHER_REFRESH_ON_PUBLISH=true
JELLYFIN_API_URL=
JELLYFIN_API_KEY=
JELLYFIN_LIBRARY_ID=

# Agent Zero (used by n8n approval poller)
AGENT_ZERO_BASE_URL=http://agent-zero:8080
AGENT_ZERO_EVENTS_TOKEN=

# Jellyfin Bridge
JELLYFIN_URL=
JELLYFIN_API_KEY=
JELLYFIN_USER_ID=
JELLYFIN_AUTOLINK=false
AUTOLINK_INTERVAL_SEC=60

# Render Webhook
RENDER_WEBHOOK_SHARED_SECRET=change_me
RENDER_AUTO_APPROVE=false

# LangExtract (provider selection)
LANGEXTRACT_PROVIDER=rule # rule|openai|gemini (openrouter/groq supported via openai-compatible base)
EXTRACT_PUBLISH_URL=http://extract-worker:8083/ingest
EXTRACT_PUBLISH_TOKEN=

# OpenAI-compatible chat providers (OpenAI/OpenRouter/Groq or local LM Studio/vLLM/NIM)
OPENAI_API_BASE=
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini
# OpenRouter alternative: set OPENAI_API_BASE=https://openrouter.ai/api
# Groq alternative: set OPENAI_API_BASE=https://api.groq.com/openai

# Gemini
GEMINI_API_KEY=
GEMINI_MODEL=gemini-1.5-flash
