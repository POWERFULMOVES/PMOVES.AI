# Core data services
QDRANT_URL=http://qdrant:6333
QDRANT_COLLECTION=pmoves_chunks
MEILI_MASTER_KEY=master_key
NEO4J_URL=bolt://neo4j:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=neo4j

# Hiâ€‘RAG v2 (gateway)
SENTENCE_MODEL=all-MiniLM-L6-v2
INDEXER_NAMESPACE=pmoves
RERANK_ENABLE=true
RERANK_MODEL=BAAI/bge-reranker-base
RERANK_TOPN=50
RERANK_K=10
HIRAG_HTTP_PORT=8086
GRAPH_BOOST=0.15
ENTITY_CACHE_TTL=60
ENTITY_CACHE_MAX=1000
NEO4J_DICT_REFRESH_SEC=60
NEO4J_DICT_LIMIT=50000
USE_MEILI=false
TAILSCALE_ONLY=false
TAILSCALE_ADMIN_ONLY=false
TAILSCALE_CIDRS=100.64.0.0/10

# Embedding providers (local-first order)
# 1) Ollama (local)
OLLAMA_URL=http://ollama:11434
OLLAMA_EMBED_MODEL=nomic-embed-text
# 2) OpenAI-compatible (LM Studio / vLLM / NVIDIA NIM)
OPENAI_COMPAT_BASE_URL=
OPENAI_COMPAT_API_KEY=
OPENAI_COMPAT_EMBED_MODEL=text-embedding-3-small
# 3) Hugging Face Inference
HF_API_KEY=
HF_EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Retrieval Eval
EVAL_HTTP_PORT=8090

# MinIO / Presign
MINIO_ENDPOINT=minio:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_SECURE=false
AWS_DEFAULT_REGION=us-east-1
ALLOWED_BUCKETS=assets,outputs
PRESIGN_SHARED_SECRET=change_me

# Supabase / PostgREST
POSTGRES_DB=pmoves
POSTGRES_USER=pmoves
POSTGRES_PASSWORD=pmoves
PGRST_DB_SCHEMA=public,pmoves_core
PGRST_DB_ANON_ROLE=anon
SUPA_REST_URL=http://postgrest:3000
# Full Supabase (optional; see docs/SUPABASE_FULL.md)
SUPABASE_JWT_SECRET=dev_jwt_secret
SUPABASE_ANON_KEY=dev_anon_key
SUPABASE_SERVICE_ROLE_KEY=dev_service_key
SUPABASE_REALTIME_SECRET=dev_realtime_secret
GOTRUE_SITE_URL=http://localhost:54323
SUPABASE_STORAGE_URL=http://storage:5000
SUPABASE_PUBLIC_STORAGE_BASE=http://localhost:5000

# Render Webhook
RENDER_WEBHOOK_SHARED_SECRET=change_me
RENDER_AUTO_APPROVE=false

# LangExtract (provider selection)
LANGEXTRACT_PROVIDER=rule # rule|openai|gemini (openrouter/groq supported via openai-compatible base)
EXTRACT_PUBLISH_URL=http://extract-worker:8083/ingest
EXTRACT_PUBLISH_TOKEN=

# OpenAI-compatible chat providers (OpenAI/OpenRouter/Groq or local LM Studio/vLLM/NIM)
OPENAI_API_BASE=
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini
# OpenRouter alternative: set OPENAI_API_BASE=https://openrouter.ai/api
# Groq alternative: set OPENAI_API_BASE=https://api.groq.com/openai

# Gemini
GEMINI_API_KEY=
GEMINI_MODEL=gemini-1.5-flash
