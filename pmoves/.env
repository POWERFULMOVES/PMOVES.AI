TZ=America/New_York

HIRAG_HTTP_PORT=8086
GRAPH_BOOST=0.15
ENTITY_CACHE_TTL=60
ENTITY_CACHE_MAX=1000
NEO4J_DICT_REFRESH_SEC=60
NEO4J_DICT_LIMIT=50000
TAILSCALE_ONLY=true
TAILSCALE_ADMIN_ONLY=true
TAILSCALE_CIDRS=100.64.0.0/10
EVAL_HTTP_PORT=8090
# Core data services
QDRANT_URL=http://qdrant:6333
QDRANT_COLLECTION=pmoves_chunks
MEILI_MASTER_KEY=iROG9SZEQXPDbnWtstNA8HmM-5QyY10k4OsOTpc99vg
NEO4J_URL=bolt://neo4j:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=pmoves4482

# Hi‑RAG v2 (gateway)
SENTENCE_MODEL=all-MiniLM-L6-v2
INDEXER_NAMESPACE=pmoves
RERANK_ENABLE=true
RERANK_MODEL=BAAI/bge-reranker-base
RERANK_TOPN=50
RERANK_K=10
HIRAG_RERANK_ENABLED=true
HIRAG_HTTP_PORT=8086
GRAPH_BOOST=0.15
ENTITY_CACHE_TTL=60
ENTITY_CACHE_MAX=1000
NEO4J_DICT_REFRESH_SEC=60
NEO4J_DICT_LIMIT=50000
USE_MEILI=false
TAILSCALE_ONLY=false
TAILSCALE_ADMIN_ONLY=false
TAILSCALE_CIDRS=100.64.0.0/10

# Embedding providers (local-first order)
# 1) Ollama (local)
OLLAMA_URL=http://ollama:11434
OLLAMA_EMBED_MODEL=nomic-embed-text
# 2) OpenAI-compatible (LM Studio / vLLM / NVIDIA NIM)
OPENAI_COMPAT_BASE_URL=
OPENAI_COMPAT_API_KEY=
OPENAI_COMPAT_EMBED_MODEL=text-embedding-3-small
# 3) Hugging Face Inference
HF_API_KEY=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
HF_EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Retrieval Eval
EVAL_HTTP_PORT=8090

# MinIO / Presign
MINIO_ENDPOINT=minio:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_SECURE=false
AWS_DEFAULT_REGION=us-east-1
ALLOWED_BUCKETS=assets,outputs
PRESIGN_SHARED_SECRET=change_me

# Supabase / PostgREST
POSTGRES_DB=pmoves
POSTGRES_USER=pmoves
POSTGRES_PASSWORD=pmoves
PGRST_DB_SCHEMA=public
PGRST_DB_ANON_ROLE=anon
SUPA_REST_URL=http://postgrest:3000
SUPABASE_REST_URL=http://postgrest:3000

# Render Webhook
RENDER_WEBHOOK_SHARED_SECRET=change_me
RENDER_AUTO_APPROVE=false

# LangExtract (provider selection)
LANGEXTRACT_PROVIDER=rule # rule|openai|gemini (openrouter/groq supported via openai-compatible base)
EXTRACT_PUBLISH_URL=http://extract-worker:8083/ingest
EXTRACT_PUBLISH_TOKEN=

# OpenAI-compatible chat providers (OpenAI/OpenRouter/Groq or local LM Studio/vLLM/NIM)
OPENAI_API_BASE=
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini
# OpenRouter alternative: set OPENAI_API_BASE=https://openrouter.ai/api
# Groq alternative: set OPENAI_API_BASE=https://api.groq.com/openai

# Gemini
GEMINI_API_KEY=
GEMINI_MODEL=gemini-2.5-flash

# n8n echo publisher convenience
DISCORD_WEBHOOK_USERNAME=PMOVES Publisher

# Publisher workflow toggles
PUBLISHER_NOTIFY_DISCORD_WEBHOOK=
PUBLISHER_REFRESH_ON_PUBLISH=true
JELLYFIN_API_URL=
JELLYFIN_API_KEY=
JELLYFIN_LIBRARY_ID=

# Geometry Bus (CHIT) — security/decoders (gateway)
CHIT_REQUIRE_SIGNATURE=false
CHIT_PASSPHRASE=
CHIT_DECRYPT_ANCHORS=false
CHIT_DECODE_TEXT=false
CHIT_DECODE_IMAGE=false
CHIT_DECODE_AUDIO=false
CHIT_CODEBOOK_PATH=datasets/structured_dataset.jsonl
CHIT_T5_MODEL=t5-small
CHIT_CLIP_MODEL=clip-ViT-B-32
CHIT_PERSIST_DB=false

# --- Added by flight-check to align with .env.example (local dev defaults) ---
# Full Supabase (optional; used by storage/realtime if enabled)
SUPABASE_JWT_SECRET=dev_jwt_secret
SUPABASE_ANON_KEY=dev_anon_key
SUPABASE_SERVICE_ROLE_KEY=dev_service_key
SUPABASE_REALTIME_SECRET=dev_realtime_secret
GOTRUE_SITE_URL=http://localhost:54323
SUPABASE_STORAGE_URL=http://storage:5000
SUPABASE_PUBLIC_STORAGE_BASE=http://localhost:5000
